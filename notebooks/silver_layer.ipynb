{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2825dba7-19bc-4c8c-9d85-cda88416558a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, upper, split, trim, when, round, lit, count\n",
    "from pyspark.sql.types import DoubleType\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import traceback\n",
    "\n",
    "# ---------------------------\n",
    "# Initialize Spark Session\n",
    "# ---------------------------\n",
    "spark = SparkSession.builder.appName(\"HealthcareSilverLayer\").getOrCreate()\n",
    "\n",
    "# ---------------------------\n",
    "# Job ID for this run\n",
    "# ---------------------------\n",
    "job_id = str(uuid.uuid4())\n",
    "\n",
    "# ---------------------------\n",
    "# Logging function\n",
    "# ---------------------------\n",
    "def log_step(step_name, status=\"INFO\", message=\"\"):\n",
    "    log_df = spark.createDataFrame([\n",
    "        Row(\n",
    "            job_id=job_id,\n",
    "            timestamp=datetime.utcnow().isoformat(),\n",
    "            step=step_name,\n",
    "            status=status,\n",
    "            message=message\n",
    "        )\n",
    "    ])\n",
    "    (\n",
    "        log_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"append\")\n",
    "        .saveAsTable(\"logs.silver_logs.log\")\n",
    "    )\n",
    "\n",
    "# ---------------------------\n",
    "# Helper function: count nulls per column\n",
    "# ---------------------------\n",
    "def null_count(df, columns):\n",
    "    return {col_name: df.filter(col(col_name).isNull()).count() for col_name in columns}\n",
    "\n",
    "try:\n",
    "    log_step(\"START\", \"INFO\", \"Healthcare silver layer pipeline started\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Load Bronze Layer\n",
    "    # ---------------------------\n",
    "    bronze_df = spark.read.table(\"processed_outputs.bronze.patient\")\n",
    "    log_step(\"LOAD_BRONZE\", \"INFO\", f\"Loaded {bronze_df.count()} rows from Bronze layer\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 1: Deduplicate and Drop Bad Rows\n",
    "    # ---------------------------\n",
    "    before_count = bronze_df.count()\n",
    "    silver_df = bronze_df.dropDuplicates()\n",
    "    after_dedup_count = silver_df.count()\n",
    "    required_cols = [\"State\", \"Sex\", \"AgeCategory\", \"GeneralHealth\"]\n",
    "    before_dropna_count = silver_df.count()\n",
    "    silver_df = silver_df.dropna(subset=required_cols)\n",
    "    after_dropna_count = silver_df.count()\n",
    "    log_step(\"DEDUPLICATE\", \"INFO\",\n",
    "             f\"Rows before dedup: {before_count}, after dedup: {after_dedup_count}, \"\n",
    "             f\"before dropna: {before_dropna_count}, after dropna: {after_dropna_count}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 2: Clean String/Text Columns\n",
    "    # ---------------------------\n",
    "    text_cols = [\"State\", \"Sex\", \"GeneralHealth\", \"SmokerStatus\", \"ECigaretteUsage\",\n",
    "                 \"RaceEthnicityCategory\", \"AgeCategory\", \"AlcoholDrinkers\"]\n",
    "    for col_name in text_cols:\n",
    "        silver_df = silver_df.withColumn(col_name, upper(trim(col(col_name))))\n",
    "    silver_df = silver_df.withColumn(\"RaceEthnicityCategory\", split(col(\"RaceEthnicityCategory\"), \",\")[0])\n",
    "    log_step(\"TEXT_CLEAN\", \"INFO\", \"Standardized string columns\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 3: Standardize Binary (Yes/No) Columns\n",
    "    # ---------------------------\n",
    "    binary_cols = [\"HadHeartAttack\", \"HadAngina\", \"HadStroke\", \"HadAsthma\", \"HadSkinCancer\",\n",
    "                   \"HadCOPD\", \"HadDepressiveDisorder\", \"HadKidneyDisease\", \"HadArthritis\",\n",
    "                   \"HadDiabetes\", \"DeafOrHardOfHearing\", \"BlindOrVisionDifficulty\",\n",
    "                   \"DifficultyConcentrating\", \"DifficultyWalking\", \"DifficultyDressingBathing\",\n",
    "                   \"DifficultyErrands\", \"AlcoholDrinkers\", \"HIVTesting\", \"FluVaxLast12\",\n",
    "                   \"PneumoVaxEver\", \"TetanusLast10Tdap\", \"HighRiskLastYear\", \"CovidPos\"]\n",
    "    pre_null_counts = null_count(silver_df, binary_cols)\n",
    "    for col_name in binary_cols:\n",
    "        silver_df = silver_df.withColumn(\n",
    "            col_name,\n",
    "            when(upper(col(col_name)) == \"YES\", 1)\n",
    "            .when(upper(col(col_name)) == \"NO\", 0)\n",
    "            .otherwise(None)\n",
    "        )\n",
    "    post_null_counts = null_count(silver_df, binary_cols)\n",
    "    log_step(\"BINARY_STANDARDIZE\", \"INFO\",\n",
    "             f\"Null counts before: {pre_null_counts}, after: {post_null_counts}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 4–7: Numeric Conversion, Null Handling\n",
    "    # ---------------------------\n",
    "    numeric_cols = [\"HeightInMeters\", \"WeightInKilograms\", \"BMI\"]\n",
    "    for col_name in numeric_cols:\n",
    "        silver_df = silver_df.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
    "\n",
    "    before_filter_count = silver_df.count()\n",
    "    silver_df = silver_df.filter(\n",
    "        (col(\"HeightInMeters\") > 0) & (col(\"WeightInKilograms\") > 0) & (col(\"BMI\") > 0)\n",
    "    )\n",
    "    after_filter_count = silver_df.count()\n",
    "\n",
    "    silver_df = silver_df.withColumn(\"BMI\", round(col(\"BMI\"), 2))\n",
    "    silver_df = silver_df.withColumn(\"HeightInMeters\", round(col(\"HeightInMeters\"), 2))\n",
    "    silver_df = silver_df.withColumn(\"WeightInKilograms\", round(col(\"WeightInKilograms\"), 1))\n",
    "\n",
    "    fill_na_dict = {\n",
    "        \"GeneralHealth\": \"MISSING\",\n",
    "        \"SmokerStatus\": \"UNKNOWN\",\n",
    "        \"ECigaretteUsage\": \"UNKNOWN\",\n",
    "        \"RaceEthnicityCategory\": \"OTHER\",\n",
    "        \"LastCheckupTime\": \"UNKNOWN\",\n",
    "        \"RemovedTeeth\": \"UNKNOWN\",\n",
    "        \"CovidPos\": 0,\n",
    "        \"HadDiabetes\": 0\n",
    "    }\n",
    "    silver_df = silver_df.fillna(fill_na_dict)\n",
    "    log_step(\"NUMERIC_CLEAN\", \"INFO\",\n",
    "             f\"Rows before numeric filter: {before_filter_count}, after filter: {after_filter_count}. \"\n",
    "             f\"Filled NAs: {fill_na_dict}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 9: Load Hospital Dimension Table\n",
    "    # ---------------------------\n",
    "    hospital_df = spark.read.table(\"processed_outputs.bronze.hospital\")\n",
    "    hospital_df = hospital_df.drop(\"Location\")\n",
    "    hospital_df = hospital_df.withColumn(\"State\", upper(trim(col(\"State\"))))\n",
    "    hospital_df = hospital_df.fillna(\"NOT AVAILABLE\")\n",
    "    hospital_df = hospital_df.withColumn(\n",
    "        \"State\",\n",
    "        when(col(\"State\").isNull() | (trim(col(\"State\")) == \"\"), lit(\"UNKNOWN\")).otherwise(col(\"State\"))\n",
    "    )\n",
    "    log_step(\"LOAD_HOSPITAL\", \"INFO\", \"Hospital dimension table loaded & cleaned\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 11: Join Patients with Hospital Info\n",
    "    # ---------------------------\n",
    "    enriched_df = silver_df.join(hospital_df, silver_df.State == hospital_df.State, \"inner\") \\\n",
    "                           .drop(hospital_df.State)\n",
    "    enriched_df = enriched_df.withColumn(\n",
    "        \"Hospital_Info_Available\",\n",
    "        when(col(\"Provider_ID\") != \"NOT AVAILABLE\", lit(1)).otherwise(lit(0))\n",
    "    )\n",
    "    log_step(\"JOIN\", \"INFO\", f\"Joined patients with hospitals. Final rows: {enriched_df.count()}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 12: Drop Unwanted Columns\n",
    "    # ---------------------------\n",
    "    drop_list = [\"TetanusLast10Tdap\", \"Location\", \"Safety_of_care_national_comparison\"]\n",
    "    enriched_df = enriched_df.drop(*drop_list)\n",
    "    log_step(\"DROP_COLUMNS\", \"INFO\", f\"Dropped columns: {drop_list}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 13: Save to Silver Layer\n",
    "    # ---------------------------\n",
    "    enriched_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .partitionBy(\"State\") \\\n",
    "        .saveAsTable(\"processed_outputs.silver.processed\")\n",
    "    log_step(\"SAVE_SILVER\", \"INFO\", \"Silver Layer data enriched & saved\")\n",
    "\n",
    "    log_step(\"END\", \"SUCCESS\", \"Pipeline completed successfully ✅\")\n",
    "\n",
    "except Exception as e:\n",
    "    log_step(\"ERROR\", \"FAIL\", traceback.format_exc())\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
